{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2fe89ab",
   "metadata": {
    "papermill": {
     "duration": 0.008622,
     "end_time": "2024-10-06T22:21:53.777974",
     "exception": false,
     "start_time": "2024-10-06T22:21:53.769352",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Sequence model\n",
    "This notebook builds onto our initial [Training-the-model](https://www.kaggle.com/code/na731ff/training-the-model) notebook. Here, we implement a sequential model using a transformer to wrap our base model, which will still be a pretrained TIMM model, which will have 1 in_channel instead of 30. \n",
    "\n",
    "## This will allow to be more flexible by allowing a different number of images per label. \n",
    "However, we still only use the fixed 30 images per label coming from [Convert-Images-to-png](https://www.kaggle.com/code/na731ff/convert-images-to-png)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af61391f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-06T22:21:53.795897Z",
     "iopub.status.busy": "2024-10-06T22:21:53.795026Z",
     "iopub.status.idle": "2024-10-06T22:22:02.493201Z",
     "shell.execute_reply": "2024-10-06T22:22:02.492201Z"
    },
    "papermill": {
     "duration": 8.709746,
     "end_time": "2024-10-06T22:22:02.495647",
     "exception": false,
     "start_time": "2024-10-06T22:21:53.785901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import gc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import random\n",
    "import psutil\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW\n",
    "import timm\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "import albumentations as A\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "from torchvision.transforms import transforms\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision.transforms import RandomAffine, GaussianBlur\n",
    "from torch.utils.checkpoint import checkpoint_sequential\n",
    "from torchvision.transforms.functional import adjust_sharpness, autocontrast\n",
    "from torch.nn.functional import interpolate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee7d6765",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T22:22:02.514285Z",
     "iopub.status.busy": "2024-10-06T22:22:02.513693Z",
     "iopub.status.idle": "2024-10-06T22:22:02.582023Z",
     "shell.execute_reply": "2024-10-06T22:22:02.581207Z"
    },
    "papermill": {
     "duration": 0.080573,
     "end_time": "2024-10-06T22:22:02.584066",
     "exception": false,
     "start_time": "2024-10-06T22:22:02.503493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_URL = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/'\n",
    "IMAGE_URL = '/kaggle/input/convert-images-to-smaller-png/Converted_smaller_images/'\n",
    "OUTPUT_DIR = 'rsna24-results'\n",
    "SEED = 7620\n",
    "DEBUG = False # if set to true, run fewer computations\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "N_WORKERS = os.cpu_count()\n",
    "IMAGE_SIZE = [224, 224]\n",
    "IN_CHANNELS = 30 # number of images stacked over each other in an np.array which constitutes the Dataset \n",
    "N_LABELS = 25\n",
    "N_CLASSES = 3 * N_LABELS\n",
    "\n",
    "EPOCHS = 100 if not DEBUG else 2\n",
    "\n",
    "GRAD_ACCUMULATION = 4\n",
    "TARGET_BATCH_SIZE = 16\n",
    "BATCH_SIZE = TARGET_BATCH_SIZE // GRAD_ACCUMULATION\n",
    "MAX_GRAD_NORM = 1.0\n",
    "EARLY_STOPPING_EPOCH = 10\n",
    "\n",
    "LEARNING_RATE = 2e-4 * TARGET_BATCH_SIZE / 32 #could implement a lr scheduler\n",
    "WEIGHT_DECAY = 1e-2\n",
    "AUGMENTATION = True\n",
    "\n",
    "P_DROPOUT = 0.2 # Dropout intensity in the transformer\n",
    "\n",
    "USE_AUTOMATIC_MIXED_PRECISION = True # can change True if using T4 or newer than Ampere\n",
    "AUGMENTATION_PROBABILITY = 0.75\n",
    "EPS = 10e-6\n",
    "\n",
    "LEVELS = ['L1/L2', 'L2/L3', 'L3/L4', 'L4/L5', 'L5/S1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eb0892b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T22:22:02.601002Z",
     "iopub.status.busy": "2024-10-06T22:22:02.600674Z",
     "iopub.status.idle": "2024-10-06T22:22:02.748285Z",
     "shell.execute_reply": "2024-10-06T22:22:02.747295Z"
    },
    "papermill": {
     "duration": 0.158398,
     "end_time": "2024-10-06T22:22:02.750602",
     "exception": false,
     "start_time": "2024-10-06T22:22:02.592204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{BASE_URL}train.csv')\n",
    "descriptions_df = pd.read_csv(f'{BASE_URL}train_series_descriptions.csv')\n",
    "coordinates_df = pd.read_csv(f'{BASE_URL}train_label_coordinates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e6196c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T22:22:02.768268Z",
     "iopub.status.busy": "2024-10-06T22:22:02.767448Z",
     "iopub.status.idle": "2024-10-06T22:22:02.809107Z",
     "shell.execute_reply": "2024-10-06T22:22:02.808182Z"
    },
    "papermill": {
     "duration": 0.052596,
     "end_time": "2024-10-06T22:22:02.811210",
     "exception": false,
     "start_time": "2024-10-06T22:22:02.758614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>instance_number</th>\n",
       "      <th>condition</th>\n",
       "      <th>level</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>series_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>8</td>\n",
       "      <td>Spinal Canal Stenosis</td>\n",
       "      <td>L1/L2</td>\n",
       "      <td>322.831858</td>\n",
       "      <td>227.964602</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>8</td>\n",
       "      <td>Spinal Canal Stenosis</td>\n",
       "      <td>L2/L3</td>\n",
       "      <td>320.571429</td>\n",
       "      <td>295.714286</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>8</td>\n",
       "      <td>Spinal Canal Stenosis</td>\n",
       "      <td>L3/L4</td>\n",
       "      <td>323.030303</td>\n",
       "      <td>371.818182</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>8</td>\n",
       "      <td>Spinal Canal Stenosis</td>\n",
       "      <td>L4/L5</td>\n",
       "      <td>335.292035</td>\n",
       "      <td>427.327434</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>8</td>\n",
       "      <td>Spinal Canal Stenosis</td>\n",
       "      <td>L5/S1</td>\n",
       "      <td>353.415929</td>\n",
       "      <td>483.964602</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_id  series_id  instance_number              condition  level  \\\n",
       "0   4003253  702807833                8  Spinal Canal Stenosis  L1/L2   \n",
       "1   4003253  702807833                8  Spinal Canal Stenosis  L2/L3   \n",
       "2   4003253  702807833                8  Spinal Canal Stenosis  L3/L4   \n",
       "3   4003253  702807833                8  Spinal Canal Stenosis  L4/L5   \n",
       "4   4003253  702807833                8  Spinal Canal Stenosis  L5/S1   \n",
       "\n",
       "            x           y series_description  \n",
       "0  322.831858  227.964602   Sagittal T2/STIR  \n",
       "1  320.571429  295.714286   Sagittal T2/STIR  \n",
       "2  323.030303  371.818182   Sagittal T2/STIR  \n",
       "3  335.292035  427.327434   Sagittal T2/STIR  \n",
       "4  353.415929  483.964602   Sagittal T2/STIR  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinates_df = pd.merge(coordinates_df, descriptions_df, on = ['study_id', 'series_id'])\n",
    "coordinates_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d74c1bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T22:22:02.829556Z",
     "iopub.status.busy": "2024-10-06T22:22:02.828700Z",
     "iopub.status.idle": "2024-10-06T22:22:02.833343Z",
     "shell.execute_reply": "2024-10-06T22:22:02.832475Z"
    },
    "papermill": {
     "duration": 0.015901,
     "end_time": "2024-10-06T22:22:02.835367",
     "exception": false,
     "start_time": "2024-10-06T22:22:02.819466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_DIR, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65e7bff9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T22:22:02.852358Z",
     "iopub.status.busy": "2024-10-06T22:22:02.852020Z",
     "iopub.status.idle": "2024-10-06T22:22:02.863728Z",
     "shell.execute_reply": "2024-10-06T22:22:02.863017Z"
    },
    "papermill": {
     "duration": 0.022317,
     "end_time": "2024-10-06T22:22:02.865605",
     "exception": false,
     "start_time": "2024-10-06T22:22:02.843288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_random_seed(seed: int = 8620, deterministic: bool = False):\n",
    "    \"\"\"Set seeds\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = deterministic  # type: ignore\n",
    "\n",
    "set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70795f61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T22:22:02.882919Z",
     "iopub.status.busy": "2024-10-06T22:22:02.882356Z",
     "iopub.status.idle": "2024-10-06T22:22:02.945932Z",
     "shell.execute_reply": "2024-10-06T22:22:02.945007Z"
    },
    "papermill": {
     "duration": 0.074458,
     "end_time": "2024-10-06T22:22:02.948034",
     "exception": false,
     "start_time": "2024-10-06T22:22:02.873576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>spinal_canal_stenosis_l1_l2</th>\n",
       "      <th>spinal_canal_stenosis_l2_l3</th>\n",
       "      <th>spinal_canal_stenosis_l3_l4</th>\n",
       "      <th>spinal_canal_stenosis_l4_l5</th>\n",
       "      <th>spinal_canal_stenosis_l5_s1</th>\n",
       "      <th>left_neural_foraminal_narrowing_l1_l2</th>\n",
       "      <th>left_neural_foraminal_narrowing_l2_l3</th>\n",
       "      <th>left_neural_foraminal_narrowing_l3_l4</th>\n",
       "      <th>left_neural_foraminal_narrowing_l4_l5</th>\n",
       "      <th>...</th>\n",
       "      <th>left_subarticular_stenosis_l1_l2</th>\n",
       "      <th>left_subarticular_stenosis_l2_l3</th>\n",
       "      <th>left_subarticular_stenosis_l3_l4</th>\n",
       "      <th>left_subarticular_stenosis_l4_l5</th>\n",
       "      <th>left_subarticular_stenosis_l5_s1</th>\n",
       "      <th>right_subarticular_stenosis_l1_l2</th>\n",
       "      <th>right_subarticular_stenosis_l2_l3</th>\n",
       "      <th>right_subarticular_stenosis_l3_l4</th>\n",
       "      <th>right_subarticular_stenosis_l4_l5</th>\n",
       "      <th>right_subarticular_stenosis_l5_s1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4003253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4646740</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7143189</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8785691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10728036</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_id spinal_canal_stenosis_l1_l2 spinal_canal_stenosis_l2_l3  \\\n",
       "0   4003253                           0                           0   \n",
       "1   4646740                           0                           0   \n",
       "2   7143189                           0                           0   \n",
       "3   8785691                           0                           0   \n",
       "4  10728036                           0                           0   \n",
       "\n",
       "  spinal_canal_stenosis_l3_l4 spinal_canal_stenosis_l4_l5  \\\n",
       "0                           0                           0   \n",
       "1                           1                           2   \n",
       "2                           0                           0   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "\n",
       "  spinal_canal_stenosis_l5_s1 left_neural_foraminal_narrowing_l1_l2  \\\n",
       "0                           0                                     0   \n",
       "1                           0                                     0   \n",
       "2                           0                                     0   \n",
       "3                           0                                     0   \n",
       "4                           0                                     0   \n",
       "\n",
       "  left_neural_foraminal_narrowing_l2_l3 left_neural_foraminal_narrowing_l3_l4  \\\n",
       "0                                     0                                     0   \n",
       "1                                     0                                     0   \n",
       "2                                     0                                     0   \n",
       "3                                     0                                     0   \n",
       "4                                     0                                     0   \n",
       "\n",
       "  left_neural_foraminal_narrowing_l4_l5  ... left_subarticular_stenosis_l1_l2  \\\n",
       "0                                     1  ...                                0   \n",
       "1                                     1  ...                                0   \n",
       "2                                     0  ...                                0   \n",
       "3                                     1  ...                                0   \n",
       "4                                     0  ...                                0   \n",
       "\n",
       "  left_subarticular_stenosis_l2_l3 left_subarticular_stenosis_l3_l4  \\\n",
       "0                                0                                0   \n",
       "1                                0                                0   \n",
       "2                                0                                0   \n",
       "3                                0                                0   \n",
       "4                                0                                0   \n",
       "\n",
       "  left_subarticular_stenosis_l4_l5 left_subarticular_stenosis_l5_s1  \\\n",
       "0                                1                                0   \n",
       "1                                2                                0   \n",
       "2                                0                                0   \n",
       "3                                0                                0   \n",
       "4                                0                                0   \n",
       "\n",
       "  right_subarticular_stenosis_l1_l2 right_subarticular_stenosis_l2_l3  \\\n",
       "0                                 0                                 0   \n",
       "1                                 0                                 1   \n",
       "2                                 0                                 0   \n",
       "3                                 0                                 0   \n",
       "4                                 0                                 0   \n",
       "\n",
       "  right_subarticular_stenosis_l3_l4 right_subarticular_stenosis_l4_l5  \\\n",
       "0                                 0                                 0   \n",
       "1                                 1                                 1   \n",
       "2                                 0                                 0   \n",
       "3                                 0                                 0   \n",
       "4                                 0                                 1   \n",
       "\n",
       "  right_subarticular_stenosis_l5_s1  \n",
       "0                                 0  \n",
       "1                                 0  \n",
       "2                                 0  \n",
       "3                                 0  \n",
       "4                                 0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition_encoding = {'Normal/Mild': 0, 'Moderate': 1, 'Severe': 2}\n",
    "\n",
    "def map_condition(condition):\n",
    "    return condition_encoding.get(condition, -100) # we need to make sure that these NA filled with -100 are not used\n",
    "\n",
    "train_df.iloc[:, 1:] = train_df.iloc[:, 1:].map(map_condition)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4a8a0a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T22:22:02.967125Z",
     "iopub.status.busy": "2024-10-06T22:22:02.966472Z",
     "iopub.status.idle": "2024-10-06T22:22:02.971245Z",
     "shell.execute_reply": "2024-10-06T22:22:02.970369Z"
    },
    "papermill": {
     "duration": 0.016414,
     "end_time": "2024-10-06T22:22:02.973164",
     "exception": false,
     "start_time": "2024-10-06T22:22:02.956750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONDITIONS = [\n",
    "    'Spinal Canal Stenosis', \n",
    "    'Left Neural Foraminal Narrowing', \n",
    "    'Right Neural Foraminal Narrowing',\n",
    "    'Left Subarticular Stenosis',\n",
    "    'Right Subarticular Stenosis'\n",
    "]\n",
    "\n",
    "LEVELS = [\n",
    "    'L1/L2',\n",
    "    'L2/L3',\n",
    "    'L3/L4',\n",
    "    'L4/L5',\n",
    "    'L5/S1',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceee4a72",
   "metadata": {
    "papermill": {
     "duration": 0.008629,
     "end_time": "2024-10-06T22:22:02.990307",
     "exception": false,
     "start_time": "2024-10-06T22:22:02.981678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Defining the Dataset\n",
    "This implementation supposedly leaves a lot of room for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5983d785",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T22:22:03.009439Z",
     "iopub.status.busy": "2024-10-06T22:22:03.008706Z",
     "iopub.status.idle": "2024-10-06T22:22:03.029390Z",
     "shell.execute_reply": "2024-10-06T22:22:03.028456Z"
    },
    "papermill": {
     "duration": 0.032704,
     "end_time": "2024-10-06T22:22:03.031551",
     "exception": false,
     "start_time": "2024-10-06T22:22:02.998847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RSNA24Dataset(Dataset):\n",
    "    def __init__(\n",
    "            self, \n",
    "            df = train_df, \n",
    "            descriptions_df = descriptions_df, \n",
    "            phase='train', \n",
    "            transform=None\n",
    "            ):\n",
    "        \n",
    "        self.df = df\n",
    "        self.descriptions_df = descriptions_df\n",
    "        self.transform = transform\n",
    "        self.phase = phase\n",
    "        self.PILToTensor = transforms.Compose([transforms.PILToTensor()])\n",
    "        self.images = {}\n",
    "        self.load_images()\n",
    "\n",
    "    def load_images(self):\n",
    "        study_ids = self.df['study_id'].unique()\n",
    "        for study_id in study_ids:\n",
    "            if study_id not in self.images:\n",
    "                self.images[study_id] = {}\n",
    "                \n",
    "                # loading Sagittal T2\n",
    "                self._load_sagittal_t2(study_id)\n",
    "                \n",
    "                # loading Sagittal T1\n",
    "                self._load_sagittal_t1(study_id)\n",
    "                \n",
    "                # loading Axial T2\n",
    "                self._load_axial_t2(study_id)\n",
    "\n",
    "    def _load_image_type(self, study_id, image_type, description):\n",
    "        description_ = description.replace(' ', '_').replace('/', '-')\n",
    "        series_id_df = self.descriptions_df.query('@study_id == study_id and @description == series_description')\n",
    "\n",
    "        if not series_id_df.empty:\n",
    "            series_id = series_id_df['series_id'].iloc[0]\n",
    "            image_paths = glob(f'{IMAGE_URL}{study_id}/{description_}/*.png')\n",
    "            if len(image_paths) == 0:\n",
    "                print(f'{image_type} Study id: {study_id} has no images')\n",
    "                return [torch.zeros(1, IMAGE_SIZE[0], IMAGE_SIZE[1]) for _ in range(10)]\n",
    "            try:\n",
    "                images = [self.PILToTensor(Image.open(path).convert('L')) for path in image_paths[:10]]\n",
    "                if len(images) < 10:\n",
    "                    images.extend([torch.zeros(1, IMAGE_SIZE[0], IMAGE_SIZE[1]) for _ in range(10 - len(images))])\n",
    "                return images\n",
    "            except Exception as e:\n",
    "                print(f'Study id: {study_id} {image_type} error while loading image: {str(e)}')\n",
    "                return [torch.zeros(1, IMAGE_SIZE[0], IMAGE_SIZE[1]) for _ in range(10)]\n",
    "        return [torch.zeros(1, IMAGE_SIZE[0], IMAGE_SIZE[1]) for _ in range(10)]\n",
    "\n",
    "    def _load_sagittal_t2(self, study_id):\n",
    "        self.images[study_id]['Sagittal T2'] = self._load_image_type(study_id, 'Sagittal T2', 'Sagittal T2/STIR')\n",
    "\n",
    "    def _load_sagittal_t1(self, study_id):\n",
    "        self.images[study_id]['Sagittal T1'] = self._load_image_type(study_id, 'Sagittal T1', 'Sagittal T1')\n",
    "\n",
    "    def _load_axial_t2(self, study_id):\n",
    "        self.images[study_id]['Axial T2'] = self._load_image_type(study_id, 'Axial T2', 'Axial T2')\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        images = []\n",
    "        row = self.df.iloc[idx]\n",
    "        study_id = int(row['study_id'])\n",
    "        labels = row[1:].values.astype(np.int64)\n",
    "        \n",
    "        for image_type in ['Sagittal T2', 'Sagittal T1', 'Axial T2']:\n",
    "            images.extend(self.images[study_id][image_type])\n",
    "\n",
    "        if sum([torch.sum(t) for t in images]) == 0:\n",
    "            raise ValueError(f'No valid images found for study_id: {study_id}')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            # Generate a random seed for this sequence\n",
    "            seed = np.random.randint(2147483647)\n",
    "\n",
    "            transformed_images = []\n",
    "            for img in images:\n",
    "                # Set the seed for this image (ensures same transform for all images in sequence)\n",
    "                np.random.seed(seed)\n",
    "                img = img.squeeze(0).numpy()  # Remove channel dimension and convert to numpy\n",
    "                transformed = self.transform(image=img)['image']\n",
    "                transformed_images.append(transformed)\n",
    "            \n",
    "            images = torch.stack(transformed_images)\n",
    "        else:\n",
    "            images = torch.stack(images)\n",
    "\n",
    "        return images, torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dab880",
   "metadata": {
    "papermill": {
     "duration": 0.008283,
     "end_time": "2024-10-06T22:22:03.048383",
     "exception": false,
     "start_time": "2024-10-06T22:22:03.040100",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data augmentation\n",
    "Taken from Kaggle winner, but for a different problem. See, for instance, [this notebook](https://www.kaggle.com/code/haqishen/1st-place-soluiton-code-small-ver) (past Kaggle competition winner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c3b3b0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T22:22:03.067223Z",
     "iopub.status.busy": "2024-10-06T22:22:03.066414Z",
     "iopub.status.idle": "2024-10-06T22:22:03.082713Z",
     "shell.execute_reply": "2024-10-06T22:22:03.081786Z"
    },
    "papermill": {
     "duration": 0.027878,
     "end_time": "2024-10-06T22:22:03.084737",
     "exception": false,
     "start_time": "2024-10-06T22:22:03.056859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.\n",
      "  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n"
     ]
    }
   ],
   "source": [
    "transforms_train = A.Compose([\n",
    "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=AUGMENTATION_PROBABILITY),\n",
    "    A.OneOf([\n",
    "        A.MotionBlur(blur_limit=5),\n",
    "        A.MedianBlur(blur_limit=5),\n",
    "        A.GaussianBlur(blur_limit=5),\n",
    "        A.GaussNoise(var_limit=(5.0, 30.0)),\n",
    "    ], p=AUGMENTATION_PROBABILITY),\n",
    "    A.OneOf([\n",
    "        A.OpticalDistortion(distort_limit=1.0),\n",
    "        A.GridDistortion(num_steps=5, distort_limit=1.),\n",
    "        A.ElasticTransform(alpha=3),\n",
    "    ], p=AUGMENTATION_PROBABILITY),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=AUGMENTATION_PROBABILITY),\n",
    "    A.Resize(IMAGE_SIZE[0], IMAGE_SIZE[1]),\n",
    "    A.CoarseDropout(max_holes=4, max_height=8, max_width=8, min_holes=1, min_height=4, min_width=4, p=AUGMENTATION_PROBABILITY),    \n",
    "    A.Normalize(mean=0.5, std=0.5),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "transforms_validation = A.Compose([\n",
    "    A.Resize(IMAGE_SIZE[0], IMAGE_SIZE[1]),\n",
    "    A.Normalize(mean=0.5, std=0.5),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "if DEBUG or not AUGMENTATION:\n",
    "    transforms_train = transforms_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd71ebe",
   "metadata": {
    "papermill": {
     "duration": 0.008476,
     "end_time": "2024-10-06T22:22:03.101702",
     "exception": false,
     "start_time": "2024-10-06T22:22:03.093226",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Let's try here the Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df1cd40e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T22:22:03.120728Z",
     "iopub.status.busy": "2024-10-06T22:22:03.119779Z",
     "iopub.status.idle": "2024-10-06T22:22:03.129743Z",
     "shell.execute_reply": "2024-10-06T22:22:03.128928Z"
    },
    "papermill": {
     "duration": 0.021589,
     "end_time": "2024-10-06T22:22:03.131647",
     "exception": false,
     "start_time": "2024-10-06T22:22:03.110058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_rsna24_dataset(num_studies=10):\n",
    "    print(\"Testing RSNA24Dataset...\")\n",
    "    \n",
    "    # Use the first num_studies rows from train_df\n",
    "    test_df = train_df.head(num_studies)\n",
    "    \n",
    "    # Create a dataset instance\n",
    "    dataset = RSNA24Dataset(df=test_df, descriptions_df=descriptions_df, phase='train', transform=transforms_train)\n",
    "    \n",
    "    # Test __len__ method\n",
    "    assert len(dataset) == num_studies, f\"Expected {num_studies} items, but got {len(dataset)}\"\n",
    "    print(f\"Dataset length: {len(dataset)} (as expected)\")\n",
    "    \n",
    "    # Test __getitem__ method for each study\n",
    "    for idx in range(num_studies):\n",
    "        try:\n",
    "            images, labels = dataset[idx]\n",
    "            \n",
    "            # Check images\n",
    "            assert images.shape == (30, 1, 224, 224), f\"Expected shape (30, 1, 224, 224), but got {images.shape}\"\n",
    "            assert images.dtype == torch.float32, f\"Expected dtype torch.float32, but got {images.dtype}\"\n",
    "            assert images.min() >= -1 and images.max() <= 1, f\"Expected values in range [-1, 1], but got [{images.min()}, {images.max()}]\"\n",
    "            \n",
    "            # Check labels\n",
    "            assert labels.shape == (25,), f\"Expected shape (25,), but got {labels.shape}\"\n",
    "            assert labels.dtype == torch.int64, f\"Expected dtype torch.int64, but got {labels.dtype}\"\n",
    "            assert all(label in [0, 1, 2] for label in labels), f\"Expected labels to be 0, 1, or 2, but got {labels.tolist()}\"\n",
    "            \n",
    "            print(f\"Study {idx+1}/{num_studies} passed all checks\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing study {idx+1}/{num_studies}: {str(e)}\")\n",
    "    \n",
    "    print(\"RSNA24Dataset test completed.\")\n",
    "\n",
    "# Run the test\n",
    "if DEBUG:\n",
    "    test_rsna24_dataset(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062686db",
   "metadata": {
    "papermill": {
     "duration": 0.008214,
     "end_time": "2024-10-06T22:22:03.148353",
     "exception": false,
     "start_time": "2024-10-06T22:22:03.140139",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define the Model\n",
    "Didn't have much time so just sticking to the stuff on the notebook we are drawing inspiration from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4ff4894",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T22:22:03.166246Z",
     "iopub.status.busy": "2024-10-06T22:22:03.165913Z",
     "iopub.status.idle": "2024-10-06T22:22:03.173853Z",
     "shell.execute_reply": "2024-10-06T22:22:03.172995Z"
    },
    "papermill": {
     "duration": 0.019169,
     "end_time": "2024-10-06T22:22:03.175777",
     "exception": false,
     "start_time": "2024-10-06T22:22:03.156608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.2, max_len=10):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # Shape: (1, max_len, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bc2b2ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T22:22:03.193982Z",
     "iopub.status.busy": "2024-10-06T22:22:03.193443Z",
     "iopub.status.idle": "2024-10-06T22:22:03.203910Z",
     "shell.execute_reply": "2024-10-06T22:22:03.202832Z"
    },
    "papermill": {
     "duration": 0.021818,
     "end_time": "2024-10-06T22:22:03.205840",
     "exception": false,
     "start_time": "2024-10-06T22:22:03.184022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResidualTransformerEncoder(nn.Module):\n",
    "    def __init__(self, d_model, nhead, num_layers, dropout):\n",
    "        super(ResidualTransformerEncoder, self).__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            ResidualTransformerEncoderLayer(d_model, nhead, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "    \n",
    "    def forward(self, src):\n",
    "        for layer in self.layers:\n",
    "            src = layer(src)\n",
    "        return self.norm(src)\n",
    "\n",
    "class ResidualTransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dropout):\n",
    "        super(ResidualTransformerEncoderLayer, self).__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model * 4, d_model)\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, src):\n",
    "        # Multi-head attention with residual connection\n",
    "        attn_output, _ = self.self_attn(src, src, src)\n",
    "        src = src + self.dropout(attn_output)\n",
    "        src = self.norm1(src)\n",
    "        \n",
    "        # Feed-forward network with residual connection\n",
    "        ff_output = self.feed_forward(src)\n",
    "        src = src + self.dropout(ff_output)\n",
    "        src = self.norm2(src)\n",
    "        \n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a5a8205",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T22:22:03.224287Z",
     "iopub.status.busy": "2024-10-06T22:22:03.223954Z",
     "iopub.status.idle": "2024-10-06T22:22:03.253787Z",
     "shell.execute_reply": "2024-10-06T22:22:03.252881Z"
    },
    "papermill": {
     "duration": 0.04156,
     "end_time": "2024-10-06T22:22:03.255749",
     "exception": false,
     "start_time": "2024-10-06T22:22:03.214189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 'tf_efficientnetv2_b3'\n",
    "class OptimizedMultiScaleEfficientNet(nn.Module):\n",
    "    def __init__(self, model_name='densenet121', pretrained=True, num_classes=256):\n",
    "        super(OptimizedMultiScaleEfficientNet, self).__init__()\n",
    "        \n",
    "        # Load the EfficientNet model\n",
    "        self.efficientnet = timm.create_model(model_name, pretrained=pretrained, features_only=True, in_chans=1)\n",
    "        \n",
    "        # Get the number of channels in each feature map\n",
    "        self.channels = self.efficientnet.feature_info.channels()\n",
    "        \n",
    "        # Select three scales: early, middle, and late\n",
    "        self.scales = [-3, -2, -1]\n",
    "        \n",
    "        # Global average pooling\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # Projection layers for each selected scale\n",
    "        self.projections = nn.ModuleList([\n",
    "            nn.Linear(self.channels[i], num_classes // 4) for i in self.scales[:2]\n",
    "        ] + [nn.Linear(self.channels[self.scales[-1]], num_classes // 2)])\n",
    "        \n",
    "        # Final fusion layer\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(num_classes, num_classes),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(num_classes, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Freeze all layers initially\n",
    "        self.freeze_all_layers()\n",
    "        self.num_unfrozen_layers = 0\n",
    "        self.unfreeze_layers(num_layers_to_unfreeze = 2)\n",
    "\n",
    "    def freeze_all_layers(self):\n",
    "        for param in self.efficientnet.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def unfreeze_layers(self, num_layers_to_unfreeze=1):\n",
    "        layers_to_unfreeze = [\n",
    "            'features_denseblock4',\n",
    "            'features_transition3',\n",
    "            'features_denseblock3',\n",
    "            'features_transition2',\n",
    "            'features_denseblock2',\n",
    "            'features_transition1',\n",
    "            'features_denseblock1',\n",
    "            'features_norm0',\n",
    "            'features_conv0'\n",
    "        ]\n",
    "        \n",
    "        curr_unfrozen = self.num_unfrozen_layers\n",
    "        \n",
    "        if curr_unfrozen >= len(layers_to_unfreeze) - 3:\n",
    "            print('All layers are trainable')\n",
    "        else:\n",
    "            for i, layer_name in enumerate(layers_to_unfreeze[curr_unfrozen: min(curr_unfrozen + num_layers_to_unfreeze, len(layers_to_unfreeze))]):\n",
    "                self.num_unfrozen_layers += 1\n",
    "                if hasattr(self.efficientnet, layer_name):\n",
    "                    for param in getattr(self.efficientnet, layer_name).parameters():\n",
    "                        param.requires_grad = True\n",
    "                    print(f\"Unfrozen layer: {layer_name}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Get features from EfficientNet\n",
    "        features = self.efficientnet(x)\n",
    "        \n",
    "        # Process selected scales\n",
    "        multi_scale_features = []\n",
    "        for i, proj in zip(self.scales, self.projections):\n",
    "            feat = features[i]\n",
    "            feat = self.gap(feat).squeeze(-1).squeeze(-1)\n",
    "            feat = proj(feat)\n",
    "            multi_scale_features.append(feat)\n",
    "        \n",
    "        # Concatenate features from all scales\n",
    "        combined_features = torch.cat(multi_scale_features, dim=1)\n",
    "        \n",
    "        # Final fusion\n",
    "        output = self.fusion(combined_features)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class ImageSequenceModel(nn.Module):\n",
    "    def __init__(self, num_classes, nhead, num_encoder_layers, reduced_dim=256, num_images=30, dropout=0.2):\n",
    "        super(ImageSequenceModel, self).__init__()\n",
    "        \n",
    "        # Use OptimizedMultiScaleEfficientNet as the base model\n",
    "        self.base_model = OptimizedMultiScaleEfficientNet(num_classes=reduced_dim)\n",
    "        \n",
    "        self.reduced_dim = reduced_dim\n",
    "        \n",
    "        # Positional encoding with fixed number of images\n",
    "        self.positional_encoding = PositionalEncoding(reduced_dim, dropout, num_images)\n",
    "        \n",
    "        # Multi-head attention layer\n",
    "        self.multihead_attn = nn.MultiheadAttention(reduced_dim, nhead, dropout=dropout, batch_first=True)\n",
    "        \n",
    "        # Residual Transformer encoder\n",
    "        self.transformer_encoder = ResidualTransformerEncoder(reduced_dim, nhead, num_encoder_layers, dropout)\n",
    "        \n",
    "        # Final classification layer\n",
    "        self.classifier = nn.Linear(reduced_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, num_images, channels, height, width = x.size()\n",
    "        \n",
    "        # Reshape to process all images at once\n",
    "        x = x.view(batch_size * num_images, channels, height, width)\n",
    "        \n",
    "        # Extract multi-scale features using the base model\n",
    "        features = self.base_model(x)  # Shape: (batch_size * num_images, reduced_dim)\n",
    "        \n",
    "        # Reshape to form a sequence\n",
    "        embeddings = features.view(batch_size, num_images, -1)  # Shape: (batch_size, num_images, reduced_dim)\n",
    "        \n",
    "        # Apply positional encoding\n",
    "        embeddings = self.positional_encoding(embeddings)\n",
    "        \n",
    "        # Apply multi-head attention\n",
    "        attn_output, _ = self.multihead_attn(embeddings, embeddings, embeddings)\n",
    "        \n",
    "        # Residual connection after multi-head attention\n",
    "        embeddings = embeddings + attn_output\n",
    "        \n",
    "        # Transformer encoding with residual connections\n",
    "        transformer_output = self.transformer_encoder(embeddings)  # Shape: (batch_size, num_images, reduced_dim)\n",
    "        \n",
    "        # Mean pooling across the sequence dimension (average across images)\n",
    "        sequence_representation = transformer_output.mean(dim=1)  # Shape: (batch_size, reduced_dim)\n",
    "        \n",
    "        # Classification\n",
    "        output = self.classifier(sequence_representation)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "130e2e00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T22:22:03.274066Z",
     "iopub.status.busy": "2024-10-06T22:22:03.273549Z",
     "iopub.status.idle": "2024-10-06T22:22:03.286487Z",
     "shell.execute_reply": "2024-10-06T22:22:03.285613Z"
    },
    "papermill": {
     "duration": 0.024053,
     "end_time": "2024-10-06T22:22:03.288319",
     "exception": false,
     "start_time": "2024-10-06T22:22:03.264266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_model_memory_usage(batch_size=1, num_images=30, image_size=(230, 230), num_classes=75, nhead=8, num_encoder_layers=4):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    model = ImageSequenceModel(\n",
    "        num_classes=num_classes,\n",
    "        nhead=nhead,\n",
    "        num_encoder_layers=num_encoder_layers,\n",
    "        reduced_dim=384,\n",
    "        num_images=num_images,\n",
    "        dropout=0.1\n",
    "    ).to(device)\n",
    "\n",
    "    dummy_input = torch.randn(batch_size, num_images, 1, *image_size).to(device)\n",
    "    dummy_target = torch.randint(0, num_classes, (batch_size,)).to(device)\n",
    "    print(f\"Input shape: {dummy_input.shape}\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    initial_memory = torch.cuda.memory_allocated(device)\n",
    "\n",
    "    try:\n",
    "        # Forward pass\n",
    "        output = model(dummy_input)\n",
    "        loss = criterion(output, dummy_target)\n",
    "\n",
    "        print(f\"Forward pass successful.\")\n",
    "        print(f\"Output shape: {output.shape}\")\n",
    "        \n",
    "        forward_memory = torch.cuda.memory_allocated(device)\n",
    "        print(f\"Memory after forward pass: {forward_memory / 1e6:.2f} MB\")\n",
    "        print(f\"Memory used in forward pass: {(forward_memory - initial_memory) / 1e6:.2f} MB\")\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        backward_memory = torch.cuda.memory_allocated(device)\n",
    "        print(f\"Memory after backward pass: {backward_memory / 1e6:.2f} MB\")\n",
    "        print(f\"Memory used in backward pass: {(backward_memory - forward_memory) / 1e6:.2f} MB\")\n",
    "\n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        final_memory = torch.cuda.memory_allocated(device)\n",
    "        print(f\"Final memory usage: {final_memory / 1e6:.2f} MB\")\n",
    "        print(f\"Total memory difference: {(final_memory - initial_memory) / 1e6:.2f} MB\")\n",
    "\n",
    "        peak_memory = torch.cuda.max_memory_allocated(device)\n",
    "        print(f\"Peak memory usage: {peak_memory / 1e6:.2f} MB\")\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error during computation: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "# Run the test\n",
    "if DEBUG:\n",
    "    test_model_memory_usage(batch_size=4, num_images=30, image_size=(224, 224), num_classes=75, nhead=16, num_encoder_layers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ad1c477",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T22:22:03.306973Z",
     "iopub.status.busy": "2024-10-06T22:22:03.306201Z",
     "iopub.status.idle": "2024-10-06T22:22:03.318034Z",
     "shell.execute_reply": "2024-10-06T22:22:03.317157Z"
    },
    "papermill": {
     "duration": 0.023247,
     "end_time": "2024-10-06T22:22:03.319958",
     "exception": false,
     "start_time": "2024-10-06T22:22:03.296711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_model_performance(batch_size=2, grad_acc=8, num_images=30, image_size=(230, 230), num_classes=75, nhead=12, num_encoder_layers=6):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    model = ImageSequenceModel(\n",
    "        num_classes=num_classes,\n",
    "        nhead=nhead,\n",
    "        num_encoder_layers=num_encoder_layers,\n",
    "        reduced_dim=512,\n",
    "        num_images=num_images,\n",
    "        dropout=0.1\n",
    "    ).to(device)\n",
    "\n",
    "    dummy_input = torch.randn(batch_size, num_images, 1, *image_size).to(device)\n",
    "    dummy_target = torch.randint(0, num_classes, (batch_size,)).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    autocast = torch.cuda.amp.autocast(enabled=USE_AUTOMATIC_MIXED_PRECISION, dtype=torch.half)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=USE_AUTOMATIC_MIXED_PRECISION, init_scale=4096)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=WEIGHT_DECAY)\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    try:\n",
    "        for i in range(grad_acc):\n",
    "            with autocast:\n",
    "                output = model(dummy_input)\n",
    "                loss = criterion(output, dummy_target)\n",
    "                loss = loss / grad_acc\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        peak_memory = torch.cuda.max_memory_allocated(device)\n",
    "        print(f\"Peak memory usage: {peak_memory / 1e6:.2f} MB\")\n",
    "        print(f\"Effective batch size: {batch_size * grad_acc}\")\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error during computation: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "# Run the test\n",
    "if DEBUG:\n",
    "    test_model_performance(batch_size=4, grad_acc=4, num_images=30, image_size=(224, 224), num_classes=75, nhead=16, num_encoder_layers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec881d6f",
   "metadata": {
    "papermill": {
     "duration": 0.008291,
     "end_time": "2024-10-06T22:22:03.336560",
     "exception": false,
     "start_time": "2024-10-06T22:22:03.328269",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Check if the model works\n",
    "Commenting these out to save memory. Somehow it does not reset when I delete. Commented out during actual training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771b5010",
   "metadata": {
    "papermill": {
     "duration": 0.008729,
     "end_time": "2024-10-06T22:22:03.353558",
     "exception": false,
     "start_time": "2024-10-06T22:22:03.344829",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9343298",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T22:22:03.372261Z",
     "iopub.status.busy": "2024-10-06T22:22:03.371582Z",
     "iopub.status.idle": "2024-10-06T22:22:03.377186Z",
     "shell.execute_reply": "2024-10-06T22:22:03.376383Z"
    },
    "papermill": {
     "duration": 0.017205,
     "end_time": "2024-10-06T22:22:03.379126",
     "exception": false,
     "start_time": "2024-10-06T22:22:03.361921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## helper functions to keep track of memory usage \n",
    "def get_ram_usage():\n",
    "    \"\"\"Returns the current CPU RAM usage in MB.\"\"\"\n",
    "    process = psutil.Process()\n",
    "    mem_info = process.memory_info()\n",
    "    return int(mem_info.rss / (1024 ** 2))  # Convert bytes to MB\n",
    "\n",
    "def get_gpu_memory_usage(device=0):\n",
    "    \"\"\"Returns the current GPU VRAM usage in MB for the specified device.\"\"\"\n",
    "    return int(torch.cuda.memory_allocated(device) / (1024 ** 2))  # Convert bytes to MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08d73181",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T22:22:03.397487Z",
     "iopub.status.busy": "2024-10-06T22:22:03.396711Z",
     "iopub.status.idle": "2024-10-06T22:22:03.407113Z",
     "shell.execute_reply": "2024-10-06T22:22:03.406461Z"
    },
    "papermill": {
     "duration": 0.021368,
     "end_time": "2024-10-06T22:22:03.408922",
     "exception": false,
     "start_time": "2024-10-06T22:22:03.387554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_optimizer_fine_grained(model, base_lr=1e-3, lr_factor=0.1):\n",
    "    # Group parameters by component, with finer granularity in the base model\n",
    "    base_model_early_params = list(model.base_model.efficientnet.features_conv0.parameters()) + \\\n",
    "                              list(model.base_model.efficientnet.features_norm0.parameters()) + \\\n",
    "                              list(model.base_model.efficientnet.features_pool0.parameters()) + \\\n",
    "                              list(model.base_model.efficientnet.features_denseblock1.parameters())\n",
    "    \n",
    "    base_model_middle_params = list(model.base_model.efficientnet.features_transition1.parameters()) + \\\n",
    "                               list(model.base_model.efficientnet.features_denseblock2.parameters()) + \\\n",
    "                               list(model.base_model.efficientnet.features_transition2.parameters())\n",
    "    \n",
    "    base_model_late_params = list(model.base_model.efficientnet.features_denseblock3.parameters()) + \\\n",
    "                             list(model.base_model.efficientnet.features_transition3.parameters()) + \\\n",
    "                             list(model.base_model.efficientnet.features_denseblock4.parameters()) + \\\n",
    "                             list(model.base_model.efficientnet.features_norm5.parameters())\n",
    "    \n",
    "    base_model_proj_params = list(model.base_model.projections.parameters()) + list(model.base_model.fusion.parameters())\n",
    "    transformer_params = list(model.multihead_attn.parameters()) + list(model.transformer_encoder.parameters())\n",
    "    classifier_params = list(model.classifier.parameters())\n",
    "\n",
    "    # Create parameter groups with different learning rates\n",
    "    param_groups = [\n",
    "        {'params': base_model_early_params, 'lr': base_lr * (lr_factor ** 2)},  # Lowest learning rate\n",
    "        {'params': base_model_middle_params, 'lr': base_lr * (lr_factor ** 1.5)},\n",
    "        {'params': base_model_late_params, 'lr': base_lr * lr_factor},\n",
    "        {'params': base_model_proj_params, 'lr': base_lr * (lr_factor ** 0.5)},\n",
    "        {'params': transformer_params, 'lr': base_lr * (lr_factor ** 0.25)},\n",
    "        {'params': classifier_params, 'lr': base_lr}  # Highest learning rate\n",
    "    ]\n",
    "\n",
    "    # Create optimizer with parameter groups\n",
    "    optimizer = AdamW(param_groups, lr=base_lr, weight_decay=0.01)\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5ae33a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T22:22:03.426996Z",
     "iopub.status.busy": "2024-10-06T22:22:03.426694Z",
     "iopub.status.idle": "2024-10-07T04:35:35.815821Z",
     "shell.execute_reply": "2024-10-07T04:35:35.814637Z"
    },
    "papermill": {
     "duration": 22414.135692,
     "end_time": "2024-10-07T04:35:37.552783",
     "exception": false,
     "start_time": "2024-10-06T22:22:03.417091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/2536897865.py:1: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  autocast = torch.cuda.amp.autocast(enabled=USE_AUTOMATIC_MIXED_PRECISION, dtype=torch.half)\n",
      "/tmp/ipykernel_23/2536897865.py:2: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=USE_AUTOMATIC_MIXED_PRECISION, init_scale=4096)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "Starting Training\n",
      "##############################\n",
      "Training length:  1678 Validation length:  297\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "387a0f55b5bd4f15b02c7074745c51fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/32.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfrozen layer: features_denseblock4\n",
      "Unfrozen layer: features_transition3\n",
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [08:24<00:00,  1.21s/it, loss=0.883516, lr=5.014e-09, max_ram_usage=CPU:4562 GPU:843]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.874785\n",
      "max CPU RAM usage: 4570, max GPU RAM usage: 843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:14<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.745720, validation wall:0.859779\n",
      "epoch:1, best loss updated from inf to 0.745720\n",
      "epoch:1, best wall_metric updated from inf to 0.859779\n",
      "Starting epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [08:40<00:00,  1.24s/it, loss=0.748714, lr=9.981e-09, max_ram_usage=CPU:4584 GPU:844]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.761642\n",
      "max CPU RAM usage: 4584, max GPU RAM usage: 844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:12<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.755455, validation wall:0.889153\n",
      "Starting epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [08:23<00:00,  1.20s/it, loss=0.968956, lr=1.495e-08, max_ram_usage=CPU:4585 GPU:844]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.763171\n",
      "max CPU RAM usage: 4585, max GPU RAM usage: 844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:12<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.747127, validation wall:0.864441\n",
      "Starting epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [08:26<00:00,  1.21s/it, loss=1.004040, lr=1.991e-08, max_ram_usage=CPU:4585 GPU:844]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.765166\n",
      "max CPU RAM usage: 4585, max GPU RAM usage: 844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:12<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.743839, validation wall:0.865927\n",
      "epoch:4, best loss updated from 0.745720 to 0.743839\n",
      "Starting epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [08:27<00:00,  1.21s/it, loss=0.715825, lr=2.488e-08, max_ram_usage=CPU:4585 GPU:844]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.761185\n",
      "max CPU RAM usage: 4585, max GPU RAM usage: 844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:13<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.750783, validation wall:0.873277\n",
      "Starting epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [08:41<00:00,  1.25s/it, loss=0.528168, lr=2.985e-08, max_ram_usage=CPU:4585 GPU:844]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.764291\n",
      "max CPU RAM usage: 4585, max GPU RAM usage: 844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:12<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.753264, validation wall:0.885000\n",
      "Starting epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [08:17<00:00,  1.19s/it, loss=0.752792, lr=3.481e-08, max_ram_usage=CPU:4585 GPU:844]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.760335\n",
      "max CPU RAM usage: 4585, max GPU RAM usage: 844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:12<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.763301, validation wall:0.875693\n",
      "Starting epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [08:25<00:00,  1.21s/it, loss=0.621087, lr=3.978e-08, max_ram_usage=CPU:4585 GPU:844]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.764135\n",
      "max CPU RAM usage: 4585, max GPU RAM usage: 844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:12<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.755734, validation wall:0.871146\n",
      "Starting epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [08:44<00:00,  1.25s/it, loss=1.011812, lr=4.475e-08, max_ram_usage=CPU:4585 GPU:844]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.759353\n",
      "max CPU RAM usage: 4585, max GPU RAM usage: 844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:12<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.752968, validation wall:0.866627\n",
      "Starting epoch 10\n",
      "Unfrozen layer: features_denseblock3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [09:16<00:00,  1.33s/it, loss=0.956790, lr=5.000e-06, max_ram_usage=CPU:4592 GPU:2662]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.767902\n",
      "max CPU RAM usage: 4592, max GPU RAM usage: 2665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:12<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.771808, validation wall:0.917785\n",
      "Starting epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [09:17<00:00,  1.33s/it, loss=1.103177, lr=5.000e-06, max_ram_usage=CPU:4592 GPU:2657]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.760465\n",
      "max CPU RAM usage: 4592, max GPU RAM usage: 2665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:13<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.746938, validation wall:0.861647\n",
      "Starting epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [09:13<00:00,  1.32s/it, loss=0.492192, lr=5.000e-06, max_ram_usage=CPU:4592 GPU:2659]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.754141\n",
      "max CPU RAM usage: 4592, max GPU RAM usage: 2665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:12<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.739221, validation wall:0.870628\n",
      "epoch:12, best loss updated from 0.743839 to 0.739221\n",
      "Starting epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [09:11<00:00,  1.32s/it, loss=0.634630, lr=5.000e-06, max_ram_usage=CPU:4592 GPU:2658]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.756724\n",
      "max CPU RAM usage: 4592, max GPU RAM usage: 2665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:12<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.742862, validation wall:0.872121\n",
      "Starting epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [09:10<00:00,  1.31s/it, loss=0.782513, lr=5.000e-06, max_ram_usage=CPU:4592 GPU:2660]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.753497\n",
      "max CPU RAM usage: 4592, max GPU RAM usage: 2665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:12<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.738924, validation wall:0.863090\n",
      "epoch:14, best loss updated from 0.739221 to 0.738924\n",
      "Starting epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [09:14<00:00,  1.32s/it, loss=0.514151, lr=5.000e-06, max_ram_usage=CPU:4592 GPU:2665]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.749649\n",
      "max CPU RAM usage: 4592, max GPU RAM usage: 2665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:12<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.741401, validation wall:0.859196\n",
      "epoch:15, best wall_metric updated from 0.859779 to 0.859196\n",
      "Starting epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [09:20<00:00,  1.34s/it, loss=0.651989, lr=5.000e-06, max_ram_usage=CPU:4594 GPU:2656]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.750850\n",
      "max CPU RAM usage: 4594, max GPU RAM usage: 2665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:12<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.755044, validation wall:0.903780\n",
      "Starting epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [09:20<00:00,  1.34s/it, loss=1.298919, lr=5.000e-06, max_ram_usage=CPU:4594 GPU:2660]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.762770\n",
      "max CPU RAM usage: 4594, max GPU RAM usage: 2666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:12<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.743100, validation wall:0.872114\n",
      "Starting epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [09:16<00:00,  1.33s/it, loss=0.852115, lr=5.000e-06, max_ram_usage=CPU:4594 GPU:2657]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.749955\n",
      "max CPU RAM usage: 4594, max GPU RAM usage: 2666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:13<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.745258, validation wall:0.882182\n",
      "Starting epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [09:28<00:00,  1.36s/it, loss=0.537852, lr=5.000e-06, max_ram_usage=CPU:4594 GPU:2657]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.748433\n",
      "max CPU RAM usage: 4594, max GPU RAM usage: 2666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:12<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.735408, validation wall:0.855303\n",
      "epoch:19, best loss updated from 0.738924 to 0.735408\n",
      "epoch:19, best wall_metric updated from 0.859196 to 0.855303\n",
      "Starting epoch 20\n",
      "Unfrozen layer: features_transition2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [09:20<00:00,  1.34s/it, loss=0.579649, lr=5.000e-06, max_ram_usage=CPU:4592 GPU:2895]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.752727\n",
      "max CPU RAM usage: 4594, max GPU RAM usage: 2895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:12<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.732983, validation wall:0.854072\n",
      "epoch:20, best loss updated from 0.735408 to 0.732983\n",
      "epoch:20, best wall_metric updated from 0.855303 to 0.854072\n",
      "Starting epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [09:22<00:00,  1.34s/it, loss=0.694799, lr=5.000e-06, max_ram_usage=CPU:4595 GPU:2892]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.748324\n",
      "max CPU RAM usage: 4595, max GPU RAM usage: 2895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:12<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.732453, validation wall:0.851338\n",
      "epoch:21, best loss updated from 0.732983 to 0.732453\n",
      "epoch:21, best wall_metric updated from 0.854072 to 0.851338\n",
      "Starting epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [09:30<00:00,  1.36s/it, loss=1.143981, lr=5.000e-06, max_ram_usage=CPU:4592 GPU:2895]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.745383\n",
      "max CPU RAM usage: 4640, max GPU RAM usage: 2895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:12<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.732243, validation wall:0.854292\n",
      "epoch:22, best loss updated from 0.732453 to 0.732243\n",
      "Starting epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [09:23<00:00,  1.34s/it, loss=0.778565, lr=5.000e-06, max_ram_usage=CPU:4591 GPU:2894]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.746266\n",
      "max CPU RAM usage: 4640, max GPU RAM usage: 2896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:13<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.741625, validation wall:0.878360\n",
      "Starting epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [09:22<00:00,  1.34s/it, loss=0.669409, lr=5.000e-06, max_ram_usage=CPU:4592 GPU:2888]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.748699\n",
      "max CPU RAM usage: 4640, max GPU RAM usage: 2896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:13<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.737470, validation wall:0.854423\n",
      "Starting epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [09:24<00:00,  1.35s/it, loss=0.742395, lr=5.000e-06, max_ram_usage=CPU:4591 GPU:2892]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.748191\n",
      "max CPU RAM usage: 4640, max GPU RAM usage: 2896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:12<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.742914, validation wall:0.852151\n",
      "Starting epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [09:28<00:00,  1.36s/it, loss=0.906344, lr=5.000e-06, max_ram_usage=CPU:4591 GPU:2892]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.745003\n",
      "max CPU RAM usage: 4640, max GPU RAM usage: 2896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:12<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.738639, validation wall:0.865132\n",
      "Starting epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [09:32<00:00,  1.37s/it, loss=0.723347, lr=5.000e-06, max_ram_usage=CPU:4592 GPU:2891]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.744401\n",
      "max CPU RAM usage: 4640, max GPU RAM usage: 2896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:12<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.735670, validation wall:0.852354\n",
      "Starting epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [09:24<00:00,  1.35s/it, loss=0.550682, lr=5.000e-06, max_ram_usage=CPU:4592 GPU:2892]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.745636\n",
      "max CPU RAM usage: 4640, max GPU RAM usage: 2896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:13<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.730743, validation wall:0.849712\n",
      "epoch:28, best loss updated from 0.732243 to 0.730743\n",
      "epoch:28, best wall_metric updated from 0.851338 to 0.849712\n",
      "Starting epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [09:28<00:00,  1.36s/it, loss=0.542613, lr=5.000e-06, max_ram_usage=CPU:4595 GPU:2887]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.744655\n",
      "max CPU RAM usage: 4640, max GPU RAM usage: 2896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:12<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.743927, validation wall:0.873017\n",
      "Starting epoch 30\n",
      "Unfrozen layer: features_denseblock2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [10:35<00:00,  1.52s/it, loss=0.601260, lr=5.000e-06, max_ram_usage=CPU:4598 GPU:4763]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.749352\n",
      "max CPU RAM usage: 4640, max GPU RAM usage: 4763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:12<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.735465, validation wall:0.869267\n",
      "Starting epoch 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [10:32<00:00,  1.51s/it, loss=0.772769, lr=5.000e-06, max_ram_usage=CPU:4598 GPU:4765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.744308\n",
      "max CPU RAM usage: 4640, max GPU RAM usage: 4765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:12<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.737538, validation wall:0.859309\n",
      "Starting epoch 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [10:32<00:00,  1.51s/it, loss=0.605375, lr=5.000e-06, max_ram_usage=CPU:4598 GPU:4766]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.743937\n",
      "max CPU RAM usage: 4640, max GPU RAM usage: 4766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:13<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.738773, validation wall:0.856385\n",
      "Starting epoch 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [10:36<00:00,  1.52s/it, loss=1.211774, lr=5.000e-06, max_ram_usage=CPU:4598 GPU:4767]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.742407\n",
      "max CPU RAM usage: 4640, max GPU RAM usage: 4767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:13<00:00,  5.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.734369, validation wall:0.864106\n",
      "Starting epoch 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [10:33<00:00,  1.51s/it, loss=0.738635, lr=5.000e-06, max_ram_usage=CPU:4598 GPU:4768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.743080\n",
      "max CPU RAM usage: 4640, max GPU RAM usage: 4768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:12<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.735711, validation wall:0.866466\n",
      "Starting epoch 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 14/419 [00:29<09:45,  1.45s/it, loss=0.841403, lr=5.000e-06, max_ram_usage=CPU:4598 GPU:4676]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN loss encountered, skipping update\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [10:38<00:00,  1.52s/it, loss=0.711236, lr=5.000e-06, max_ram_usage=CPU:4598 GPU:4763]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.746790\n",
      "max CPU RAM usage: 4640, max GPU RAM usage: 4772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:12<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.735455, validation wall:0.866101\n",
      "Starting epoch 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [10:34<00:00,  1.52s/it, loss=0.830175, lr=5.000e-06, max_ram_usage=CPU:4598 GPU:4763]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.744409\n",
      "max CPU RAM usage: 4640, max GPU RAM usage: 4772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:12<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.735311, validation wall:0.863491\n",
      "Starting epoch 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [10:33<00:00,  1.51s/it, loss=1.217796, lr=5.000e-06, max_ram_usage=CPU:4598 GPU:4763]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.744406\n",
      "max CPU RAM usage: 4640, max GPU RAM usage: 4772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:12<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.738601, validation wall:0.874054\n",
      "Starting epoch 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419/419 [10:30<00:00,  1.50s/it, loss=0.661406, lr=5.000e-06, max_ram_usage=CPU:4598 GPU:4766]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.744076\n",
      "max CPU RAM usage: 4640, max GPU RAM usage: 4772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:12<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.734342, validation wall:0.863219\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "autocast = torch.cuda.amp.autocast(enabled=USE_AUTOMATIC_MIXED_PRECISION, dtype=torch.half)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=USE_AUTOMATIC_MIXED_PRECISION, init_scale=4096)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "training_index, validation_index = train_test_split(range(len(train_df)), test_size=0.15, random_state=123)\n",
    "\n",
    "if DEBUG:\n",
    "    training_index = training_index[:32]\n",
    "    validation_index = validation_index[:32]\n",
    "\n",
    "print('#' * 30)\n",
    "print(f'Starting Training')\n",
    "print('#' * 30)\n",
    "print('Training length: ', len(training_index), 'Validation length: ', len(validation_index))\n",
    "training_rows = train_df.iloc[training_index]\n",
    "validation_rows = train_df.iloc[validation_index]\n",
    "\n",
    "start_time = time.time()\n",
    "max_training_time = 9 * 3600  # 9 hours in seconds\n",
    "\n",
    "training_dataset = RSNA24Dataset(training_rows, phase='train', transform=transforms_train)\n",
    "training_dataloader = DataLoader(\n",
    "    training_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    "    num_workers=N_WORKERS\n",
    ")\n",
    "\n",
    "validation_dataset = RSNA24Dataset(validation_rows, phase='val', transform=transforms_validation)\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    "    num_workers=N_WORKERS\n",
    ")\n",
    "\n",
    "model = ImageSequenceModel(\n",
    "            num_classes=75,\n",
    "            nhead=16,\n",
    "            num_encoder_layers=8,\n",
    "            reduced_dim=384,\n",
    "            num_images=30,\n",
    "            dropout=0.2\n",
    "        )\n",
    "\n",
    "model.to(device)\n",
    "optimizer = get_optimizer_fine_grained(model, base_lr=5e-4, lr_factor=0.01)\n",
    "\n",
    "# Define warmup steps and total steps\n",
    "num_warmup_steps = EPOCHS // 10 * len(training_dataloader) // GRAD_ACCUMULATION\n",
    "num_training_steps = num_total_steps = EPOCHS * len(training_dataloader) // GRAD_ACCUMULATION\n",
    "\n",
    "# Create a custom learning rate scheduler with warmup\n",
    "class WarmupCosineSchedule(CosineAnnealingWarmRestarts):\n",
    "    def __init__(self, optimizer, num_warmup_steps, num_training_steps, **kwargs):\n",
    "        self.num_warmup_steps = num_warmup_steps\n",
    "        super().__init__(optimizer, T_0=num_training_steps, **kwargs)\n",
    "\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch < self.num_warmup_steps:\n",
    "            return [base_lr * (self.last_epoch + 1) / self.num_warmup_steps for base_lr in self.base_lrs]\n",
    "        return super().get_lr()\n",
    "\n",
    "# Create the scheduler with warmup\n",
    "scheduler = WarmupCosineSchedule(\n",
    "    optimizer,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    num_training_steps=num_training_steps,\n",
    "    T_mult=1,  # Multiplier for increasing T_0 after a restart\n",
    "    eta_min=5e-8  # Minimum learning rate\n",
    ")\n",
    "\n",
    "weights = torch.tensor([1.0, 2.0, 4.0])\n",
    "criterion = nn.CrossEntropyLoss(weight=weights.to(device))\n",
    "criterion2 = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "best_loss = float('inf')\n",
    "best_wall = float('inf')\n",
    "es_step = 0\n",
    "\n",
    "max_cpu_ram_usage = 0\n",
    "max_gpu_ram_usage = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print(f'Starting epoch {epoch}')\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    if epoch % 10 == 0 and epoch > 0:\n",
    "        model.base_model.unfreeze_layers()\n",
    "        # Recreate optimizer to update learning rates for newly unfrozen layers\n",
    "        optimizer = get_optimizer_fine_grained(model, base_lr=5e-4, lr_factor=0.1)\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    with tqdm(training_dataloader, leave=True) as loaded_items:\n",
    "        optimizer.zero_grad()\n",
    "        for idx, (x, labels) in enumerate(loaded_items):\n",
    "            x = x.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            with torch.autograd.set_detect_anomaly(True):\n",
    "                with autocast:\n",
    "                    loss = 0\n",
    "                    output = model(x)\n",
    "                    for idx_label in range(N_LABELS):\n",
    "                        prediction = output[:, idx_label * 3 : idx_label * 3 + 3]\n",
    "                        actual_label = labels[:, idx_label]\n",
    "                        loss += criterion(prediction, actual_label) / N_LABELS\n",
    "                        \n",
    "                    if torch.isnan(loss):\n",
    "                        print(\"NaN loss encountered, skipping update\")\n",
    "                        continue\n",
    "                    \n",
    "                    total_loss += loss.item()\n",
    "                    if GRAD_ACCUMULATION > 1:\n",
    "                        loss /= GRAD_ACCUMULATION\n",
    "\n",
    "                cpu_ram_before = get_ram_usage()\n",
    "                gpu_ram_before = get_gpu_memory_usage()\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM or 1e9)\n",
    "\n",
    "                if (idx + 1) % GRAD_ACCUMULATION == 0:\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    optimizer.zero_grad()\n",
    "                    scheduler.step()\n",
    "\n",
    "                loaded_items.set_postfix(\n",
    "                    OrderedDict(\n",
    "                        loss=f'{loss.item() * GRAD_ACCUMULATION:.6f}',\n",
    "                        lr=f'{optimizer.param_groups[0][\"lr\"]:.3e}',\n",
    "                        max_ram_usage=f'CPU:{cpu_ram_before} GPU:{gpu_ram_before}'\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                max_cpu_ram_usage = max(max_cpu_ram_usage, cpu_ram_before)\n",
    "                max_gpu_ram_usage = max(max_gpu_ram_usage, gpu_ram_before)\n",
    "\n",
    "    train_loss = total_loss / len(training_dataloader)\n",
    "    print(f'train_loss:{train_loss:.6f}')\n",
    "    print(f'max CPU RAM usage: {max_cpu_ram_usage}, max GPU RAM usage: {max_gpu_ram_usage}')\n",
    "    \n",
    "    #### model evaluation phase ####\n",
    "        \n",
    "    total_loss = 0\n",
    "    output_predictions = []\n",
    "    row_names = []\n",
    "\n",
    "    model.eval()\n",
    "    with tqdm(validation_dataloader, leave=True) as loaded_items:\n",
    "        with torch.no_grad():\n",
    "            for idx, (x, labels) in enumerate(loaded_items):\n",
    "                x = x.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                with autocast:\n",
    "                    loss = 0\n",
    "                    loss_ema = 0\n",
    "                    output = model(x)\n",
    "                    for idx_label in range(N_LABELS):\n",
    "                        prediction = output[:, idx_label * 3 : idx_label * 3 + 3]\n",
    "                        actual_label = labels[:, idx_label]\n",
    "                        loss += criterion(prediction, actual_label) / N_LABELS\n",
    "\n",
    "                        output_prediction = prediction.float()\n",
    "                        output_predictions.append(output_prediction.cpu())\n",
    "                        row_names.append(actual_label.cpu())\n",
    "\n",
    "                    total_loss += loss.item()\n",
    "\n",
    "    validation_loss = total_loss / len(validation_dataloader)\n",
    "\n",
    "    output_predictions = torch.cat(output_predictions, dim = 0)\n",
    "    row_names = torch.cat(row_names)\n",
    "    validation_wall = criterion2(output_predictions, row_names)\n",
    "\n",
    "    print(f'Validation loss: {validation_loss:.6f}, validation wall:{validation_wall:.6f}')\n",
    "\n",
    "    if validation_loss < best_loss or validation_wall < best_wall:\n",
    "        es_step = 0\n",
    "        if device != 'cuda:0':\n",
    "            model.to('cuda:0')\n",
    "\n",
    "        if validation_loss < best_loss:\n",
    "            print(f'epoch:{epoch}, best loss updated from {best_loss:.6f} to {validation_loss:.6f}')\n",
    "            best_loss = validation_loss\n",
    "\n",
    "        if validation_wall < best_wall:\n",
    "            print(f'epoch:{epoch}, best wall_metric updated from {best_wall:.6f} to {validation_wall:.6f}')\n",
    "            best_wall = validation_wall\n",
    "            model_path = f'{OUTPUT_DIR}/best_wall_model.pt'\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "        if device != 'cuda:0': # why do we need to do this again?\n",
    "            model.to(device)\n",
    "\n",
    "    else:\n",
    "        es_step += 1\n",
    "        if es_step >= EARLY_STOPPING_EPOCH:\n",
    "            print('Early stopping')\n",
    "            break\n",
    "            \n",
    "    elapsed_time = time.time() - start_time\n",
    "    if elapsed_time > max_training_time:\n",
    "        print(f'Training time limit of {max_training_time/3600:.1f} hours reached. Stopping training.')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad57819",
   "metadata": {
    "papermill": {
     "duration": 2.790553,
     "end_time": "2024-10-07T04:35:43.165736",
     "exception": false,
     "start_time": "2024-10-07T04:35:40.375183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8561470,
     "sourceId": 71549,
     "sourceType": "competition"
    },
    {
     "sourceId": 199589058,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22438.044188,
   "end_time": "2024-10-07T04:35:49.097268",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-06T22:21:51.053080",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "280d626d1dd3482586a9fba229bdea48": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "29046b799a6140798e0aa823e4a4bcde": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3064e40c2aaa4e7eb17a82773d60d378": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "387a0f55b5bd4f15b02c7074745c51fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4bba44a00646411480cf6a099d800ef0",
        "IPY_MODEL_b56be0e674724c1d86fdd0f5693c4db4",
        "IPY_MODEL_c5127546023a4df2a045a0f782da3b35"
       ],
       "layout": "IPY_MODEL_52e5150c049f45bbbf69e39fbbe9effe"
      }
     },
     "4bba44a00646411480cf6a099d800ef0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_280d626d1dd3482586a9fba229bdea48",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_9fb3537794d446e4915318fb4e0d97cb",
       "value": "model.safetensors:â€‡100%"
      }
     },
     "52e5150c049f45bbbf69e39fbbe9effe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "996f2503837f4ffda0990fcab925890d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9fb3537794d446e4915318fb4e0d97cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b56be0e674724c1d86fdd0f5693c4db4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3064e40c2aaa4e7eb17a82773d60d378",
       "max": 32334434.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_996f2503837f4ffda0990fcab925890d",
       "value": 32334434.0
      }
     },
     "c5127546023a4df2a045a0f782da3b35": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f9ba54adab1c437cbb8edf815b1dd7ae",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_29046b799a6140798e0aa823e4a4bcde",
       "value": "â€‡32.3M/32.3Mâ€‡[00:00&lt;00:00,â€‡124MB/s]"
      }
     },
     "f9ba54adab1c437cbb8edf815b1dd7ae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
