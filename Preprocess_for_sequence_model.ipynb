{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5927209",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-05T08:55:11.581006Z",
     "iopub.status.busy": "2024-10-05T08:55:11.580502Z",
     "iopub.status.idle": "2024-10-05T08:55:13.510939Z",
     "shell.execute_reply": "2024-10-05T08:55:13.509778Z"
    },
    "papermill": {
     "duration": 1.943425,
     "end_time": "2024-10-05T08:55:13.513895",
     "exception": false,
     "start_time": "2024-10-05T08:55:11.570470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pydicom\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import re\n",
    "import numpy as np\n",
    "from skimage import exposure\n",
    "from scipy.ndimage import gaussian_filter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5da10b4",
   "metadata": {
    "papermill": {
     "duration": 0.00715,
     "end_time": "2024-10-05T08:55:13.528797",
     "exception": false,
     "start_time": "2024-10-05T08:55:13.521647",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this notebook we attempt to convert the pydicom images into normalised png images we can then directly use for training. We draw inspiration from [this notebook](https://www.kaggle.com/code/itsuki9180/rsna2024-lsdc-making-dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df878a8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T08:55:13.546203Z",
     "iopub.status.busy": "2024-10-05T08:55:13.544969Z",
     "iopub.status.idle": "2024-10-05T08:55:13.552444Z",
     "shell.execute_reply": "2024-10-05T08:55:13.551181Z"
    },
    "papermill": {
     "duration": 0.019,
     "end_time": "2024-10-05T08:55:13.555304",
     "exception": false,
     "start_time": "2024-10-05T08:55:13.536304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_URL = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/'\n",
    "EPS = 1e-6\n",
    "GRAYSCALE = 255\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "SAGITTAL_START_X = 0.4\n",
    "SAGITTAL_END_X = 0.8\n",
    "SAGITTAL_START_Y = 0.1\n",
    "SAGITTAL_END_Y = 0.9\n",
    "AXIAL_START_X = 0.3\n",
    "AXIAL_END_X = 0.7\n",
    "AXIAL_START_Y = 1.0 - 0.85\n",
    "AXIAL_END_Y = 1.0 - 0.35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6501f237",
   "metadata": {
    "papermill": {
     "duration": 0.006951,
     "end_time": "2024-10-05T08:55:13.569554",
     "exception": false,
     "start_time": "2024-10-05T08:55:13.562603",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We need to check here to see if we can improve the quality of the images in this conversion (we are using interpolation with cv2.INTER_CUBIC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ffea546",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T08:55:13.585869Z",
     "iopub.status.busy": "2024-10-05T08:55:13.585381Z",
     "iopub.status.idle": "2024-10-05T08:55:13.638566Z",
     "shell.execute_reply": "2024-10-05T08:55:13.637408Z"
    },
    "papermill": {
     "duration": 0.064827,
     "end_time": "2024-10-05T08:55:13.641569",
     "exception": false,
     "start_time": "2024-10-05T08:55:13.576742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(BASE_URL + 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "496bb1a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T08:55:13.657784Z",
     "iopub.status.busy": "2024-10-05T08:55:13.657404Z",
     "iopub.status.idle": "2024-10-05T08:55:13.674623Z",
     "shell.execute_reply": "2024-10-05T08:55:13.673170Z"
    },
    "papermill": {
     "duration": 0.028357,
     "end_time": "2024-10-05T08:55:13.677173",
     "exception": false,
     "start_time": "2024-10-05T08:55:13.648816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1975"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df['study_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "334d1045",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T08:55:13.693854Z",
     "iopub.status.busy": "2024-10-05T08:55:13.693472Z",
     "iopub.status.idle": "2024-10-05T08:55:13.714679Z",
     "shell.execute_reply": "2024-10-05T08:55:13.713645Z"
    },
    "papermill": {
     "duration": 0.032725,
     "end_time": "2024-10-05T08:55:13.717429",
     "exception": false,
     "start_time": "2024-10-05T08:55:13.684704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_descriptions = pd.read_csv(BASE_URL + 'train_series_descriptions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "099d28d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T08:55:13.733965Z",
     "iopub.status.busy": "2024-10-05T08:55:13.733556Z",
     "iopub.status.idle": "2024-10-05T08:55:13.741305Z",
     "shell.execute_reply": "2024-10-05T08:55:13.740217Z"
    },
    "papermill": {
     "duration": 0.019352,
     "end_time": "2024-10-05T08:55:13.744267",
     "exception": false,
     "start_time": "2024-10-05T08:55:13.724915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1975"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_ids = train_descriptions['study_id'].unique()\n",
    "len(study_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a991597",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T08:55:13.761726Z",
     "iopub.status.busy": "2024-10-05T08:55:13.761312Z",
     "iopub.status.idle": "2024-10-05T08:55:13.769384Z",
     "shell.execute_reply": "2024-10-05T08:55:13.768115Z"
    },
    "papermill": {
     "duration": 0.020335,
     "end_time": "2024-10-05T08:55:13.772791",
     "exception": false,
     "start_time": "2024-10-05T08:55:13.752456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sagittal T2/STIR' 'Sagittal T1' 'Axial T2']\n"
     ]
    }
   ],
   "source": [
    "description_list = train_descriptions['series_description'].unique()\n",
    "print(description_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f07ab72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T08:55:13.790997Z",
     "iopub.status.busy": "2024-10-05T08:55:13.789980Z",
     "iopub.status.idle": "2024-10-05T08:55:13.796321Z",
     "shell.execute_reply": "2024-10-05T08:55:13.795138Z"
    },
    "papermill": {
     "duration": 0.017922,
     "end_time": "2024-10-05T08:55:13.798812",
     "exception": false,
     "start_time": "2024-10-05T08:55:13.780890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "518570cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T08:55:13.817998Z",
     "iopub.status.busy": "2024-10-05T08:55:13.817215Z",
     "iopub.status.idle": "2024-10-05T08:55:13.833539Z",
     "shell.execute_reply": "2024-10-05T08:55:13.832171Z"
    },
    "papermill": {
     "duration": 0.029339,
     "end_time": "2024-10-05T08:55:13.836275",
     "exception": false,
     "start_time": "2024-10-05T08:55:13.806936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analyze_image(image):\n",
    "    \"\"\"Analyze image properties to determine the best normalization method.\"\"\"\n",
    "    \n",
    "    histogram = cv2.calcHist([image], [0], None, [256], [0, 256])\n",
    "    histogram = histogram.flatten() / histogram.sum()\n",
    "    \n",
    "    # Calculate image statistics\n",
    "    mean = np.mean(image)\n",
    "    std = np.std(image)\n",
    "    dynamic_range = image.max() - image.min()\n",
    "    \n",
    "    # Calculate histogram entropy\n",
    "    entropy = -np.sum(histogram * np.log2(histogram + 1e-7))\n",
    "    \n",
    "    return {\n",
    "        'mean': mean,\n",
    "        'std': std,\n",
    "        'dynamic_range': dynamic_range,\n",
    "        'entropy': entropy\n",
    "    }\n",
    "\n",
    "def adaptive_normalize_image(image, lower_percentile=1, upper_percentile=99):\n",
    "    \"\"\"\n",
    "    Dynamically choose and apply the best normalization method based on image properties.\n",
    "    \"\"\"\n",
    "    # Ensure image is in float format and in range [0, 1]\n",
    "    min_val = image.min()\n",
    "    max_val = image.max()\n",
    "    eps = 1e-6  # Small epsilon value to avoid division by near-zero\n",
    "    if max_val - min_val > eps:\n",
    "        image_float = ((image - min_val) / (max_val - min_val)).astype(float)\n",
    "    else:\n",
    "        # If all pixels have very similar values, return a uniform image\n",
    "        return np.zeros_like(image, dtype=np.uint8)\n",
    "    \n",
    "    # Analyze image\n",
    "    stats = analyze_image((image_float * 255).astype(np.uint8))\n",
    "    \n",
    "    # Determine normalization method based on image properties\n",
    "    if stats['dynamic_range'] < 75:  # Low contrast image\n",
    "        return exposure.equalize_adapthist(image_float, clip_limit=0.03)\n",
    "    elif stats['entropy'] < 6:  # Image with limited intensity levels\n",
    "        return exposure.equalize_hist(image_float)\n",
    "    elif stats['mean'] < 50 and stats['std'] < 30:  # Dark image with low variance\n",
    "        # Apply gamma correction\n",
    "        gamma = 1 - stats['mean'] / 255  # Adaptive gamma\n",
    "        return exposure.adjust_gamma(image_float, gamma)\n",
    "    elif stats['mean'] > 150:  # Very bright image\n",
    "        # Apply logarithmic correction\n",
    "        return exposure.adjust_log(image_float, 1)\n",
    "    else:\n",
    "        # For well-balanced images, apply mild contrast stretching\n",
    "        p_low, p_high = np.percentile(image_float, (lower_percentile, upper_percentile))\n",
    "        return exposure.rescale_intensity(image_float, in_range=(p_low, p_high))\n",
    "\n",
    "# Final normalization function\n",
    "def normalize_image(image):\n",
    "    normalized = adaptive_normalize_image(image)\n",
    "    return (normalized * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6cb32de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T08:55:13.853945Z",
     "iopub.status.busy": "2024-10-05T08:55:13.853303Z",
     "iopub.status.idle": "2024-10-05T08:55:13.881521Z",
     "shell.execute_reply": "2024-10-05T08:55:13.880326Z"
    },
    "papermill": {
     "duration": 0.04017,
     "end_time": "2024-10-05T08:55:13.884194",
     "exception": false,
     "start_time": "2024-10-05T08:55:13.844024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def crop_sagittal_images(images, lower_percentile=20, upper_percentile=95, sigma=1, target_width_ratio=0.6, padding_ratio=0.1, edge_threshold=10):\n",
    "    \"\"\"\n",
    "    Detect the x-range and y-range by looking at the brightness of the normalized images,\n",
    "    center the spine, crop to a target width ratio, add padding, and remove dark edges.\n",
    "    Returns the cropped images and the start coordinates.\n",
    "    \"\"\"\n",
    "    \n",
    "    num_images = len(images)\n",
    "    image = images[num_images // 2]\n",
    "    assert np.sum(image) > 0\n",
    "    \n",
    "    # Determine the horizontal and vertical ranges\n",
    "    vertical_median = np.median(image, axis=0)\n",
    "    \n",
    "    # Detect and remove dark edges\n",
    "    left_edge = 0\n",
    "    right_edge = image.shape[1] - 1\n",
    "    top_edge = 0\n",
    "    bottom_edge = image.shape[0] - 1\n",
    "    \n",
    "    while left_edge < image.shape[1] and np.mean(image[:, left_edge]) < edge_threshold:\n",
    "        left_edge += 1\n",
    "    \n",
    "    while right_edge > 0 and np.mean(image[:, right_edge]) < edge_threshold:\n",
    "        right_edge -= 1\n",
    "    \n",
    "    while top_edge < image.shape[0] and np.mean(image[top_edge, :]) < edge_threshold:\n",
    "        top_edge += 1\n",
    "    \n",
    "    while bottom_edge > 0 and np.mean(image[bottom_edge, :]) < edge_threshold:\n",
    "        bottom_edge -= 1\n",
    "    \n",
    "    # Focus on the central region of the image\n",
    "    center_x = (left_edge + right_edge) // 2\n",
    "    central_width = (right_edge - left_edge) // 2\n",
    "    central_start = max(left_edge, center_x - central_width // 2)\n",
    "    central_end = min(right_edge, center_x + central_width // 2)\n",
    "    \n",
    "    # Use dynamic thresholding based on the central region\n",
    "    central_vertical_median = vertical_median[central_start:central_end]\n",
    "    lower_threshold = np.percentile(central_vertical_median, lower_percentile)\n",
    "    upper_threshold = np.percentile(central_vertical_median, upper_percentile)\n",
    "    \n",
    "    smoothed_median = gaussian_filter(central_vertical_median, sigma=sigma)\n",
    "    \n",
    "    # Find regions above lower threshold and below upper threshold in the central region\n",
    "    relevant_indices = np.where((smoothed_median > lower_threshold) & (smoothed_median < upper_threshold))[0]\n",
    "    \n",
    "    if len(relevant_indices) == 0:\n",
    "        # If no relevant region is found, use the full central width\n",
    "        x_start = central_start\n",
    "        x_end = central_end\n",
    "    else:\n",
    "        x_start = central_start + relevant_indices[0]\n",
    "        x_end = central_start + relevant_indices[-1]\n",
    "    \n",
    "    # Calculate the center of the detected region\n",
    "    center = (x_start + x_end) // 2\n",
    "    \n",
    "    # Calculate the target width (minimum half of the original width)\n",
    "    target_width = max(int(target_width_ratio * (right_edge - left_edge)), (right_edge - left_edge) // 2)\n",
    "    \n",
    "    # Calculate padding\n",
    "    padding = int(padding_ratio * (right_edge - left_edge))\n",
    "    \n",
    "    # Detect and exclude bright noisy regions on the left\n",
    "    left_region = vertical_median[left_edge:center]\n",
    "    left_smoothed = gaussian_filter(left_region, sigma=sigma)\n",
    "    left_bright_threshold = np.percentile(left_smoothed, 98)  # Adjust this percentile as needed\n",
    "    left_bright_indices = np.where(left_smoothed > left_bright_threshold)[0]\n",
    "    \n",
    "    if len(left_bright_indices) > 0:\n",
    "        # Find the rightmost bright region on the left\n",
    "        last_bright_left = left_bright_indices[-1] + left_edge\n",
    "        # Adjust x_start to exclude the bright region\n",
    "        x_start = max(x_start, last_bright_left)\n",
    "    \n",
    "    # Detect and exclude bright noisy regions on the right\n",
    "    right_region = vertical_median[center:right_edge]\n",
    "    right_smoothed = gaussian_filter(right_region, sigma=sigma)\n",
    "    right_bright_threshold = np.percentile(right_smoothed, 98)  # Adjust this percentile as needed\n",
    "    right_bright_indices = np.where(right_smoothed > right_bright_threshold)[0]\n",
    "    \n",
    "    if len(right_bright_indices) > 0:\n",
    "        # Find the leftmost bright region on the right\n",
    "        first_bright_right = right_bright_indices[0] + center\n",
    "        # Adjust x_end to exclude the bright region\n",
    "        x_end = min(x_end, first_bright_right)\n",
    "    \n",
    "    # Ensure the spine is centered in the final crop\n",
    "    crop_width = min(target_width, x_end - x_start)\n",
    "    center = (x_start + x_end) // 2\n",
    "    x_start = max(left_edge, center - crop_width // 2 - padding)\n",
    "    x_end = min(right_edge, x_start + crop_width + 2 * padding)\n",
    "    \n",
    "    # Ensure the crop is at least 1/3 of the original width\n",
    "    min_crop_width = image.shape[1] // 3\n",
    "    crop_width = max(crop_width, min_crop_width)\n",
    "    \n",
    "    x_start = max(left_edge, center - crop_width // 2 - padding)\n",
    "    x_end = min(right_edge, x_start + crop_width + 2 * padding)\n",
    "    \n",
    "    # If the crop is still too narrow, expand it while keeping the center\n",
    "    if x_end - x_start < min_crop_width:\n",
    "        extra_width = min_crop_width - (x_end - x_start)\n",
    "        x_start = max(left_edge, x_start - extra_width // 2)\n",
    "        x_end = min(right_edge, x_end + extra_width // 2)\n",
    "        \n",
    "        # If we hit the image edges, shift the crop to ensure minimum width\n",
    "        if x_start == left_edge:\n",
    "            x_end = min(right_edge, x_start + min_crop_width)\n",
    "        elif x_end == right_edge:\n",
    "            x_start = max(left_edge, x_end - min_crop_width)\n",
    "    # Ensure the crop is at least half the original width\n",
    "    if x_end - x_start < (right_edge - left_edge) // 2:\n",
    "        extra_width = ((right_edge - left_edge) // 2) - (x_end - x_start)\n",
    "        x_start = max(left_edge, x_start - extra_width // 2)\n",
    "        x_end = min(right_edge, x_end + extra_width // 2)\n",
    "    \n",
    "    # Adjust vertical cropping\n",
    "    y_start = max(top_edge, int(SAGITTAL_START_Y * image.shape[0]))\n",
    "    y_end = min(bottom_edge, int(SAGITTAL_END_Y * image.shape[0]))\n",
    "    \n",
    "    return [image[y_start:y_end, x_start:x_end] for image in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b97867df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T08:55:13.901324Z",
     "iopub.status.busy": "2024-10-05T08:55:13.900908Z",
     "iopub.status.idle": "2024-10-05T08:55:13.908886Z",
     "shell.execute_reply": "2024-10-05T08:55:13.907648Z"
    },
    "papermill": {
     "duration": 0.019438,
     "end_time": "2024-10-05T08:55:13.911314",
     "exception": false,
     "start_time": "2024-10-05T08:55:13.891876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def crop_axial_images(images, flipped = [False, False]):\n",
    "    ''' \n",
    "    Cropping Axial images based on robust statistical analysis on the label coordinates.\n",
    "    Crop images and get the coordinates of the new top left corner \n",
    "    Could use optimisation\n",
    "    Currently does not handle images of different size in the same scan well\n",
    "    '''\n",
    "    \n",
    "    shape = images[0].shape\n",
    "    \n",
    "    x_start = round(shape[1] * AXIAL_START_X)\n",
    "    x_end = round(shape[1] * AXIAL_END_X)\n",
    "    y_start = round(shape[0] * AXIAL_START_Y)\n",
    "    y_end = round(shape[0] * AXIAL_END_Y)\n",
    "    \n",
    "    return [image[y_start: y_end, x_start: x_end] for image in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d3741ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T08:55:13.928395Z",
     "iopub.status.busy": "2024-10-05T08:55:13.927994Z",
     "iopub.status.idle": "2024-10-05T08:55:13.933703Z",
     "shell.execute_reply": "2024-10-05T08:55:13.932600Z"
    },
    "papermill": {
     "duration": 0.017178,
     "end_time": "2024-10-05T08:55:13.936238",
     "exception": false,
     "start_time": "2024-10-05T08:55:13.919060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_z_value(dicom):\n",
    "    return dicom.ImagePositionPatient[2]\n",
    "\n",
    "def extract_slice_thickness(dicom):\n",
    "    return dicom.SliceThickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04639593",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T08:55:13.954325Z",
     "iopub.status.busy": "2024-10-05T08:55:13.953175Z",
     "iopub.status.idle": "2024-10-05T08:55:13.972509Z",
     "shell.execute_reply": "2024-10-05T08:55:13.971384Z"
    },
    "papermill": {
     "duration": 0.031156,
     "end_time": "2024-10-05T08:55:13.975274",
     "exception": false,
     "start_time": "2024-10-05T08:55:13.944118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_axial_images(study_id, destination_path):\n",
    "    '''\n",
    "    Write axial images to a destination path\n",
    "    '''\n",
    "    series_ids = train_descriptions[(train_descriptions['study_id'] == study_id) & \n",
    "                                        (train_descriptions['series_description'] == 'Axial T2')]['series_id']\n",
    "    \n",
    "    if len(series_ids) == 0:\n",
    "        print(f\"No images found for Axial study_id: {study_id}\")\n",
    "        return\n",
    "    \n",
    "    consolidated_scan = []\n",
    "    z_values = []\n",
    "    slice_thicknesses = []\n",
    "    \n",
    "    for series_id in series_ids:\n",
    "        image_paths = glob(f'{BASE_URL}/train_images/{study_id}/{series_id}/*.dcm')\n",
    "        image_paths.sort(key=natural_keys)\n",
    "        \n",
    "        for path in image_paths:\n",
    "            try:\n",
    "                dcm = pydicom.dcmread(path)\n",
    "                slice_thicknesses.append(extract_slice_thickness(dcm))\n",
    "                z_value = extract_z_value(dcm)\n",
    "                \n",
    "                image = normalize_image(dcm.pixel_array)\n",
    "                if dcm.ImageOrientationPatient[0] < 0:\n",
    "                    image = np.fliplr(image)\n",
    "                if dcm.ImageOrientationPatient[4] < 0:\n",
    "                    image = np.flipud(image)\n",
    "                \n",
    "                consolidated_scan.append(image)\n",
    "                z_values.append(z_value)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {path}: {str(e)}\")\n",
    "    \n",
    "    if not consolidated_scan:\n",
    "        print(f\"No images found for Axial study_id: {study_id}\")\n",
    "        return\n",
    "    \n",
    "    sorted_indices = np.argsort(z_values)\n",
    "    consolidated_scan = [consolidated_scan[i] for i in sorted_indices]\n",
    "    z_values = [z_values[i] for i in sorted_indices]\n",
    "    \n",
    "    min_slice_thickness = min(slice_thicknesses)\n",
    "    filtered_scan = []\n",
    "    filtered_z_values = []\n",
    "    \n",
    "    for i, (image, z_value) in enumerate(zip(consolidated_scan, z_values)):\n",
    "        if not filtered_z_values or abs(z_value - filtered_z_values[-1]) >= min_slice_thickness / 2:\n",
    "            filtered_scan.append(image)\n",
    "            filtered_z_values.append(z_value)\n",
    "\n",
    "    # Select 10 evenly spaced images from filtered_scan\n",
    "    num_images = len(filtered_scan)\n",
    "    if num_images > 10:\n",
    "        step = len(filtered_scan) / 10.0\n",
    "        start = len(filtered_scan) / 2.0 - 4.0 * step\n",
    "        end = len(filtered_scan) + 0.0001\n",
    "        selected_indices = [max(0, int(i - 0.50001)) for i in np.arange(start, end, step)]\n",
    "        assert len(selected_indices) == 10\n",
    "    else:\n",
    "        print('Not enough images to select 10 evenly spaced images, Axial study_id:', study_id)\n",
    "        selected_indices = range(num_images)\n",
    "    \n",
    "    images = [filtered_scan[i] for i in selected_indices]\n",
    "    cropped_images = crop_axial_images(images)\n",
    "    images = [cv2.resize(cropped_image, IMAGE_SIZE[::-1], interpolation = cv2.INTER_CUBIC) for cropped_image in cropped_images]\n",
    "\n",
    "    normalized_images = [normalize_image(image) for image in images]\n",
    "    for idx, image in enumerate(normalized_images):\n",
    "        cv2.imwrite(f'{destination_path}/{idx:02d}.png', image)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c664987d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T08:55:13.993426Z",
     "iopub.status.busy": "2024-10-05T08:55:13.992961Z",
     "iopub.status.idle": "2024-10-05T08:55:14.009216Z",
     "shell.execute_reply": "2024-10-05T08:55:14.007880Z"
    },
    "papermill": {
     "duration": 0.028665,
     "end_time": "2024-10-05T08:55:14.011846",
     "exception": false,
     "start_time": "2024-10-05T08:55:13.983181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_sagittal_images(study_id, destination_path, series_description):\n",
    "    '''\n",
    "    Write sagittal images to a destination path\n",
    "    '''\n",
    "    series_ids = train_descriptions[(train_descriptions['study_id'] == study_id) & \n",
    "                                    (train_descriptions['series_description'] == series_description)]\n",
    "    \n",
    "    if len(series_ids) == 0:\n",
    "        print(f\"No images found for Sagittal study_id: {study_id} series_description: {series_description}\")\n",
    "        return\n",
    "    \n",
    "    series_id = series_ids['series_id'].values[0]\n",
    "    image_paths = glob(f'{BASE_URL}/train_images/{study_id}/{series_id}/*.dcm')\n",
    "    image_paths.sort(key=natural_keys)\n",
    "    \n",
    "    try:\n",
    "        first_image = pydicom.dcmread(image_paths[0])\n",
    "        num_images = len(image_paths)\n",
    "\n",
    "        flipped = [first_image.ImageOrientationPatient[1] < 0, first_image.ImageOrientationPatient[5] > 0]\n",
    "\n",
    "        images = [normalize_image(pydicom.dcmread(path).pixel_array) for idx, path in enumerate(image_paths)]\n",
    "\n",
    "        if flipped[0]:\n",
    "            images = [np.fliplr(image) for image in images]\n",
    "        if flipped[1]:\n",
    "            images = [np.flipud(image) for image in images]\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Sagittal T2 study_id: {study_id}. Error: {str(e)}\")\n",
    "\n",
    "    if num_images > 10:\n",
    "        step = len(images) / 10.0\n",
    "        start = len(images) / 2.0 - 4.0 * step\n",
    "        end = len(images) + 0.0001\n",
    "        selected_indices = [max(0, int(i - 0.50001)) for i in np.arange(start, end, step)]\n",
    "        assert len(selected_indices) == 10\n",
    "    else:\n",
    "        print(f'Not enough images to select 10 evenly spaced images, Sagittal study_id: {study_id} series_id: {series_id}')\n",
    "        selected_indices = range(len(images))\n",
    "    \n",
    "    images = [images[i] for i in selected_indices]\n",
    "\n",
    "    cropped_images = crop_sagittal_images(images)\n",
    "    normalized_images = [normalize_image(image) for image in cropped_images]\n",
    "    resized_images = [cv2.resize(image, IMAGE_SIZE[::-1], interpolation = cv2.INTER_CUBIC) for image in normalized_images]\n",
    "    for idx, image in enumerate(resized_images):\n",
    "        cv2.imwrite(f'{destination_path}/{idx:02d}.png', image)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bd6ec4",
   "metadata": {
    "papermill": {
     "duration": 0.007558,
     "end_time": "2024-10-05T08:55:14.027412",
     "exception": false,
     "start_time": "2024-10-05T08:55:14.019854",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Dividing the image by scan (see comment in code below), I am guessing to avoid using the uniformative outer images of the saggital scans where you see nothing (although why a big step? Surely you wouldn't want to not use some of the good images... to further explain or improve)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b144104",
   "metadata": {
    "papermill": {
     "duration": 0.008051,
     "end_time": "2024-10-05T08:55:14.044577",
     "exception": false,
     "start_time": "2024-10-05T08:55:14.036526",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loop that converts the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42b95289",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T08:55:14.062094Z",
     "iopub.status.busy": "2024-10-05T08:55:14.061631Z",
     "iopub.status.idle": "2024-10-05T10:23:32.896180Z",
     "shell.execute_reply": "2024-10-05T10:23:32.891761Z"
    },
    "papermill": {
     "duration": 5298.851149,
     "end_time": "2024-10-05T10:23:32.903588",
     "exception": false,
     "start_time": "2024-10-05T08:55:14.052439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 33/1975 [01:30<1:39:34,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough images to select 10 evenly spaced images, Sagittal study_id: 82066307 series_id: 2003554076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 344/1975 [15:18<1:36:44,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough images to select 10 evenly spaced images, Sagittal study_id: 767443105 series_id: 3268622861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 928/1975 [41:23<33:58,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough images to select 10 evenly spaced images, Sagittal study_id: 2053213309 series_id: 2972736368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 1126/1975 [50:23<32:29,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No images found for Sagittal study_id: 2492114990 series_description: Sagittal T1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 1272/1975 [56:38<33:07,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No images found for Sagittal study_id: 2780132468 series_description: Sagittal T1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 1378/1975 [1:01:40<20:31,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No images found for Sagittal study_id: 3008676218 series_description: Sagittal T2/STIR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 1408/1975 [1:02:59<22:47,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough images to select 10 evenly spaced images, Sagittal study_id: 3074144108 series_id: 845353263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1517/1975 [1:07:54<18:50,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough images to select 10 evenly spaced images, Axial study_id: 3303545110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1975/1975 [1:28:18<00:00,  2.68s/it]\n"
     ]
    }
   ],
   "source": [
    "for study_id in tqdm(study_ids):\n",
    "    for description in description_list:\n",
    "        description_ = description.replace(' ', '_').replace('/', '-')\n",
    "\n",
    "        destination = f'Converted_smaller_images/{study_id}/{description_}'\n",
    "        os.makedirs(destination, exist_ok=True)\n",
    "        \n",
    "        if description == 'Axial T2':\n",
    "            write_axial_images(study_id, destination)\n",
    "        elif description == 'Sagittal T2/STIR':\n",
    "            write_sagittal_images(study_id, destination, description)\n",
    "        elif description == 'Sagittal T1':\n",
    "            write_sagittal_images(study_id, destination, description)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb4ea42",
   "metadata": {
    "papermill": {
     "duration": 0.195068,
     "end_time": "2024-10-05T10:23:33.293006",
     "exception": false,
     "start_time": "2024-10-05T10:23:33.097938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8561470,
     "sourceId": 71549,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5306.933413,
   "end_time": "2024-10-05T10:23:34.736848",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-05T08:55:07.803435",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
